{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arjun Bedi\n",
    "### Deep Learning \n",
    "### Agents attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo\n",
    "- front end (streamlit, maxwell)\n",
    "    - textbox, dropdown\n",
    "- add backend capabilities to take in data from dropdown\n",
    "- prompt engineering if time\n",
    "- improve Rag agent/test crew\n",
    "- VIDEO\n",
    "- MEDIUM ARTICLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Can maybe make this a class and pass it into the agent that needs to use this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# initialize_vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_annotated_script(file_path):\n",
    "        \"\"\"\n",
    "        Parse an annotated script file into structured format\n",
    "        Returns a list of dictionaries for each scene in the script\n",
    "        \"\"\"\n",
    "        # Creates structure of output\n",
    "        scenes = []\n",
    "        current_scene = {\n",
    "            \"scene_heading\": \"\",\n",
    "            \"description\": \"\",\n",
    "            \"dialog\": [],\n",
    "            \"speakers\": [],\n",
    "            \"script_id\": \"\"\n",
    "        }\n",
    "        script_id = file_path.split('_')[-2]\n",
    "        # Read file\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "        # For each line\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            # Split into label and actual text\n",
    "            if ': ' in line:\n",
    "                label, content = line.split(': ', 1)\n",
    "                # If label is a new scene heading, add previous to scene\n",
    "                if label == 'scene_heading':\n",
    "                    if current_scene[\"scene_heading\"]:\n",
    "                        current_scene[\"script_id\"] = script_id\n",
    "                        scenes.append(current_scene)\n",
    "                        current_scene = {\n",
    "                            \"scene_heading\": content,\n",
    "                            \"description\": \"\",\n",
    "                            \"dialog\": [],\n",
    "                            \"speakers\": [],\n",
    "                            \"script_id\": script_id\n",
    "                        }\n",
    "                    else:\n",
    "                        current_scene[\"scene_heading\"] = content\n",
    "                        current_scene[\"script_id\"] = script_id\n",
    "        \n",
    "                elif label == 'text':\n",
    "                    current_scene[\"description\"] += content + \" \"\n",
    "                elif label == 'dialog':\n",
    "                    current_scene[\"dialog\"].append(content)\n",
    "                elif label == 'speaker_heading':\n",
    "                    current_scene[\"speakers\"].append(content)\n",
    "        # Add final scene         \n",
    "        if current_scene[\"scene_heading\"]:\n",
    "            current_scene[\"script_id\"] = script_id\n",
    "            scenes.append(current_scene)\n",
    "            \n",
    "        return scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGAgent:\n",
    "    def __init__(self):\n",
    "        self.embeddings = OpenAIEmbeddings()\n",
    "        # self.vector_store = vector_store\n",
    "        # consider making the above a class and passing it in\n",
    "\n",
    "    def parse_data(self, data_dir: str) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Load script data from the annotations directory  \n",
    "        Args:\n",
    "            data_dir: Base directory (data) containing manual_annotations\n",
    "        \"\"\"\n",
    "        structured_data = []\n",
    "        # Determine which annotations to use\n",
    "        anno_path = os.path.join(data_dir, 'manual_annotations', 'manual_annotations', '*.txt')    \n",
    "        # Load all annotation files\n",
    "        for anno_file in glob.glob(anno_path):\n",
    "            # extend() adds all elements from that list to the structured_data list\n",
    "                # A list of dictionaries explaining the scene\n",
    "            structured_data.extend(parse_annotated_script(anno_file))\n",
    "        return structured_data\n",
    "\n",
    "    def initialize_vector_store(self, data_dir: str):\n",
    "        \"\"\"\n",
    "        Initialize the vector store with script examples from the annotations\n",
    "        \n",
    "        Args:\n",
    "            data_dir: Base directory containing manual_annotations\n",
    "        \"\"\"\n",
    "        structured_data = self.parse_data(data_dir)\n",
    "        # Load metadata\n",
    "        metadata_path = os.path.join(data_dir, 'movie_meta_data.csv')\n",
    "        metadata_df = pd.read_csv(metadata_path)\n",
    "        # Convert imdbid to string with leading zeros to match file naming\n",
    "        metadata_df['imdbid'] = metadata_df['imdbid'].astype(str).str.zfill(7)\n",
    "        # Prepare documents for indexing\n",
    "        documents = []\n",
    "        # Convert structured scenes to searchable text\n",
    "        for scene in structured_data:\n",
    "            # Extract script filename to get imdbid\n",
    "            script_id = scene['script_id']\n",
    "            # Get metadata for this script\n",
    "            if not metadata_df[metadata_df['imdbid'] == script_id].empty:\n",
    "                script_meta = metadata_df[metadata_df['imdbid'] == script_id].iloc[0] \n",
    "            else:\n",
    "                script_meta = None\n",
    "            # Format dialog with speakers for better context\n",
    "            dialog_with_speakers = []\n",
    "            for speaker, line in zip(scene['speakers'], scene['dialog']):\n",
    "                if speaker and line:\n",
    "                    temp = speaker+\": \"+line\n",
    "                    dialog_with_speakers.append(temp)\n",
    "            # Build metadata section\n",
    "            metadata_text = \"\"\n",
    "            if script_meta is not None:\n",
    "                metadata_text = f\"\"\"\n",
    "                Title: {script_meta['title']}\n",
    "                Genre: {script_meta['genres']}\n",
    "                Keywords: {script_meta['keywords']}\n",
    "                Director: {script_meta['directors']}\n",
    "                \"\"\"   \n",
    "            scene_text = f\"\"\"\n",
    "            {metadata_text}\n",
    "            Scene: {scene['scene_heading']}\n",
    "            Description: {scene['description']}\n",
    "            Dialog:\n",
    "            {chr(10).join(dialog_with_speakers)}\n",
    "            \"\"\"\n",
    "            documents.append(scene_text)\n",
    "        # Split documents into chunks\n",
    "        # Create a text splitter that breaks documents into smaller chunks\n",
    "        # - chunk_size=1000: Each chunk will contain approximately 1000 characters\n",
    "        # - chunk_overlap=200: Consecutive chunks will overlap by 200 characters to maintain context\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200\n",
    "        )\n",
    "        \n",
    "        # Convert our raw document strings into LangChain Document objects\n",
    "        # This creates a list of Document objects that contain the text and any metadata\n",
    "        texts = text_splitter.create_documents(documents)\n",
    "        \n",
    "        # Create a FAISS vector store from our documents\n",
    "        # - FAISS is a library for efficient similarity search\n",
    "        # - This converts each document into vector embeddings using the specified embeddings model\n",
    "        # - The vector store allows us to find semantically similar documents to a query\n",
    "        self.vector_store = FAISS.from_documents(texts, self.embeddings)\n",
    "    \n",
    "    def retrieve_relevant_content(self, query: str, k: int = 3) -> List[str]:\n",
    "        \"\"\"\n",
    "        Retrieve relevant script examples based on the query\n",
    "        \"\"\"\n",
    "        if not self.vector_store:\n",
    "            return []\n",
    "        \n",
    "        results = self.vector_store.similarity_search(query, k=k)\n",
    "        return [doc.page_content for doc in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WriterAgent:\n",
    "    def __init__(self, apiKey: str, temperature: float = 0.7):\n",
    "        self.llm = ChatOpenAI(temperature=temperature, api_key=apiKey)\n",
    "        self.prompt = PromptTemplate(\n",
    "            input_variables=[\"genre\", \"setting\", \"idea\", \"examples\"],\n",
    "            template=\"\"\"You are an experienced screenwriter. Write a compelling scene based on the following criteria:\n",
    "            Genre: {genre}\n",
    "            Setting: {setting}\n",
    "            Core Idea: {idea}\n",
    "            \n",
    "            Here are some example scenes for reference:\n",
    "            {examples}\n",
    "            \n",
    "            Write a scene that follows proper screenplay format:\n",
    "            1. Start with a scene heading (location, time, etc.)\n",
    "            2. Include clear scene descriptions\n",
    "            3. Format dialog with speaker names in caps\n",
    "            \n",
    "            Make the scene original and engaging while maintaining professional formatting.\n",
    "            \"\"\"\n",
    "        )\n",
    "        self.chain = LLMChain(llm=self.llm, prompt=self.prompt)\n",
    "    \n",
    "    def write_scene(self, genre: str, setting: str, idea: str, director_style: Optional[str], length: str,examples: List[str]) -> str:\n",
    "        \"\"\"Generate a scene based on the given criteria and examples\"\"\"\n",
    "        examples_text = \"\\n\\n\".join(examples) if examples else \"No examples provided.\"\n",
    "        return self.chain.run(\n",
    "            genre=genre,\n",
    "            setting=setting,\n",
    "            idea=idea,\n",
    "            director_style=director_style,\n",
    "            length=length,\n",
    "            examples=examples_text\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EditorAgent:\n",
    "    def __init__(self, apiKey: str, temperature: float = 0.3):\n",
    "        self.llm = ChatOpenAI(temperature=temperature, api_key=apiKey)\n",
    "        self.prompt = PromptTemplate(\n",
    "            input_variables=[\"scene\", \"genre\"],\n",
    "            template=\"\"\"You are an experienced script editor. Review and improve the following scene:\n",
    "\n",
    "            Scene:\n",
    "            {scene}\n",
    "\n",
    "            Genre: {genre}\n",
    "\n",
    "            Improve the scene while maintaining proper screenplay format:\n",
    "            1. Scene headings (INT/EXT, location, time)\n",
    "            2. Action descriptions (present tense, visual)\n",
    "            3. Character names in caps\n",
    "            4. Dialog formatting and parentheticals\n",
    "            5. Proper spacing and structure\n",
    "\n",
    "            Consider these specific points:\n",
    "            1. Ensure dialogue flows naturally\n",
    "            2. Verify scene pacing matches genre expectations\n",
    "            3. Check for clear character motivations\n",
    "            4. Enhance visual descriptions\n",
    "\n",
    "            Focus on:\n",
    "            1. Dialogue authenticity\n",
    "            2. Scene pacing\n",
    "            3. Character development\n",
    "            4. Visual storytelling\n",
    "            5. Genre consistency\n",
    "\n",
    "            Return the improved scene in proper screenplay format.\n",
    "            \"\"\"\n",
    "        )\n",
    "        self.chain = LLMChain(llm=self.llm, prompt=self.prompt)\n",
    "    \n",
    "    def edit_scene(self, scene: str, genre: str) -> str:\n",
    "        \"\"\"\n",
    "        Edit and improve the given scene\n",
    "        \"\"\"\n",
    "        return self.chain.run(\n",
    "            scene=scene,\n",
    "            genre=genre\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScriptGenerationCrew:\n",
    "    def __init__(self, apiKey: str):\n",
    "        self.rag_agent = RAGAgent(api_key = apiKey)\n",
    "        self.writer_agent = WriterAgent(api_key = apiKey)\n",
    "        self.editor_agent = EditorAgent(api_key = apiKey)\n",
    "        \n",
    "    def initialize_with_data(self, data_dir: str, use_manual: bool = True):\n",
    "        \"\"\"\n",
    "        Initialize the RAG agent with annotated scripts\n",
    "        \"\"\"\n",
    "        self.rag_agent.initialize_vector_store(data_dir, use_manual)\n",
    "    \n",
    "    def generate_scene(self, \n",
    "                      genre: str, \n",
    "                      setting: str, \n",
    "                      idea: str,\n",
    "                      director_style: str,\n",
    "                      length: str) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Generate a complete scene using all agents\n",
    "        \"\"\"\n",
    "        \n",
    "        # 1. Retrieve relevant examples\n",
    "        relevant_examples = self.rag_agent.retrieve_relevant_content(\n",
    "            f\"{genre} {setting} {idea}\"\n",
    "        )\n",
    "        \n",
    "        # 2. Generate initial scene\n",
    "        initial_scene = self.writer_agent.write_scene(\n",
    "            genre=genre,\n",
    "            setting=setting,\n",
    "            idea=idea,\n",
    "            director_style=director_style,\n",
    "            length=length,\n",
    "            examples=relevant_examples\n",
    "        )\n",
    "            \n",
    "        # 3. Edit initial scene and generate final scene\n",
    "        final_scene = self.editor_agent.edit_scene(\n",
    "            scene=initial_scene,\n",
    "            genre=genre\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"initial_scene\": initial_scene,\n",
    "            \"final_scene\": final_scene,\n",
    "            \"examples_used\": relevant_examples\n",
    "        }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
